# -*- coding: utf-8 -*-
"""sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQRAnDbY923sLDjJStaZVCiY3XMcRsf1
"""

!pip install transformers datasets torch scikit-learn pandas tqdm

import torch

# Check if GPU is available
print("GPU Available:", torch.cuda.is_available())

# Check GPU name
!nvidia-smi

import torch
import pandas as pd
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

dataset = load_dataset("imdb")
print(dataset)

model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

tokenized_datasets = dataset.map(tokenize_function, batched=True)

train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(10000))  # Use 10k samples
test_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(2000))    # Use 2k samples

model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
model.to("cuda")  # Move model to GPU

def compute_metrics(pred):
    from sklearn.metrics import accuracy_score, precision_recall_fscore_support

    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    id2label = {0: "negative", 1: "positive"}
    pred_labels = [id2label[p] for p in preds]
    true_labels = [id2label[l] for l in labels]

    acc = accuracy_score(true_labels, pred_labels)
    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='weighted')

    return {
        "accuracy": acc,
        "f1": f1,
        "precision": precision,
        "recall": recall,
    }

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics,
)
trainer.train()

model.save_pretrained("sentiment_model")
tokenizer.save_pretrained("sentiment_model")

model.config.label2id = {"negative": 0, "positive": 1}
model.config.id2label = {0: "negative", 1: "positive"}

# Save the model and tokenizer
model.save_pretrained("sentiment_model")
tokenizer.save_pretrained("sentiment_model")

from transformers import pipeline

sentiment_classifier = pipeline("sentiment-analysis", model="sentiment_model")

text = "I love this movie! It was amazing."
result = sentiment_classifier(text)

print(result)

!pip install huggingface_hub

!pip install transformers huggingface_hub

model.save_pretrained("sentiment_model")
tokenizer.save_pretrained("sentiment_model")

from huggingface_hub import notebook_login

notebook_login()

from huggingface_hub import upload_folder

# Upload the entire "sentiment_model" folder to Hugging Face
upload_folder(
    folder_path="sentiment_model",
    repo_id="dharanesh21114/sentiment-analysis-model1",  # Replace with your Hugging Face username
    repo_type="model"
)

from transformers import AutoModelForSequenceClassification, AutoTokenizer
from huggingface_hub import notebook_login

# Login to Hugging Face
notebook_login()

# Define your model name (use your Hugging Face username)
model_name = "dharanesh21114/sentiment-analysis-model1"  # Replace with your Hugging Face username

# Save model and tokenizer
model.save_pretrained(model_name)
tokenizer.save_pretrained(model_name)

# Push to Hugging Face (this creates a new repo if it doesn't exist)
model.push_to_hub(model_name)
tokenizer.push_to_hub(model_name)